# 1.11.0 Release ðŸŽ‰

{% note noteType="Tip" %}
**3rd December 2025**
{% /note %}

You can find the GitHub release [here](https://github.com/open-metadata/OpenMetadata/releases/tag/1.11.0-release).

## Features

### Ask Collate

AskCollate is our AI-powered conversational agent that gives you natural-language access to your data catalog and analytics. It combines metadata intelligence with direct data access, helping you discover, understand, analyze, and manage your data assets through simple, intuitive conversations.

#### Key capabilities

Semantic Search: Instantly locate data assets using natural-language queries with advanced filters such as owner, domain, tag, certification, tier, and more.

Metadata Updates: Enrich your catalog by updating descriptions, owners, tags, and other metadata directly through conversational commands.

Text-to-SQL Analysis: Convert plain-English questions into complex SQL queries to retrieve and analyze real-time data from your warehouse (read-only).

Instant Visualizations: Automatically transform SQL results into interactive bar, line, pie, and area charts---right inside the chat.

Lineage & Impact: Explore upstream and downstream dependencies to visualize data flow and assess the potential impact of changes.

Data Quality RCA: Diagnose data-quality issues and trace how test failures propagate across your pipelines.

Data Quality Planner: Generate data quality tests instantaneously using context from your metadata and the entity descriptive statistics

Business Glossary Management: Build and maintain a unified data vocabulary by defining terms, synonyms, and hierarchical relationships through chat.

### Ask Collate Slack Integration

You can now use AskCollate directly within Slack! This integration brings the full power of AskCollate to the place where your teams already collaborate, making it easier than ever to ask questions and access data context the moment you need it.

Simply mention @AskCollate in any channel or thread to tap into your data instantly.

### SQL Studio
Collate has always been the central hub to discover and understand your data, track transformations and lineage, profiling, and data quality, all in one place.

With 1.11, we're taking this a step further by giving your users the ability to query and analyze data directly within Collate.

SQL Studio lets users create personal connections to existing services and start running SQL queries while exploring the catalog.

As a service owner, you maintain full control over which services are available in SQL Studio and how users authenticate---whether through SSO, OAuth, or basic credentials.

Version 1.11 introduces support for Snowflake, BigQuery, and Trino, with additional engines coming in future releases.

### Data Quality as Code

Define and execute data quality tests programmatically using Python, with results automatically published to OpenMetadata's Data Observability dashboard. Integrate validation directly into your transformation pipelines with circuit breaker patterns to prevent bad data from reaching production tables.

Two validation approaches:

TestRunner --- Validate data already loaded in tables. Reference any table by its fully qualified name (FQN), add any test cases, then execute tests and automatically push results back to OpenMetadata. Ideal for post-load validation and monitoring.

DataFrameValidator --- Validate data inline during ETL pipelines. Acts as a circuit breaker to prevent bad data from being loaded. Define on_success and on_failure callbacks to control pipeline behavior. Supports chunked processing for large datasets. Optionally publish results to a specific table in OpenMetadata.

What happens when tests run:

Results automatically sync to OpenMetadata's Data Quality tab. Failed tests generate incidents with detailed failure reasons (e.g., "minimum value below zero: -521"). Incident alert icons appear on affected tables. The Overview tab shows passing and failing dimensions at a glance.

Why use it:

Centralize data quality test logic in version control tools. Provide reusable validation libraries for data engineers. Execute tests as part of your pipeline, not as a separate process. Maintain visibility in Collate while managing logic externally.

### Data Quality Dimensionality

You can now create dimension-level data quality tests that automatically segment results by categorical column values, providing granular visibility into data quality across different data segments.

## What's New

When adding a test case in the Data Observability tab, select "Dimension Level" to associate one or more dimension columns (e.g., status, region, product category) with your column-level test. The new configuration panel provides guidance on use cases and allows you to select multiple dimensions for multi-dimensional analysis.

Test cases with dimensions display a badge indicator showing the number of associated dimensions, making them easy to identify in your test case list.

A new "Dimensionality" tab in test results provides:

- A calendar heatmap showing pass/fail status across all dimension values over time

- A summary table with status, impact score, dimension value, and last run timestamp for each segment

- Drill-down capability to view historical execution trends for any specific dimension value

Impact scores help you quickly identify which dimension values are contributing the most failures based on affected row counts.

Why It Matters:

Previously, testing data quality across different categorical segments required writing custom SQL queries (e.g., SELECT ... WHERE status = 'completed') and maintaining separate test cases for each known value. When new dimension values appeared in your data, you had to manually create additional tests. With dimension-level test cases, a single test automatically covers all current and future values in your dimension column, eliminating maintenance overhead while providing deeper insights into where data quality issues occur.

### Notification Templates

You can now fully customize the content and format of alert notifications delivered to Slack, Microsoft Teams, Google Chat, or email.

Manage templates globally or per-alert

Navigate to Settings â†’ Notifications â†’ Templates to view and manage all notification templates. From here you can edit system default templates (which apply globally) or create new reusable templates available across your organization.

Build dynamic templates with placeholders

Use double curly brace syntax to insert dynamic fields that automatically populate when alerts trigger:

- {{entity.name}} -- Entity display name

- {{entity.owners}} -- Entity owners

- {{entity.description}} -- Entity description

- {{entity.href}} -- Direct link to the entity

- And more

Add conditional logic and rich formatting

Templates support conditional formatting with {{#if}}, {{else}}, and {{/if}} blocks. The rich text editor lets you add bold, italic, code blocks, images, links to assets, and other formatting.

Validate before saving

Click Validate to check your template syntax before saving. Invalid placeholders or syntax errors are highlighted so you can fix them before deployment.

Flexible template assignment

When creating an alert, choose to use the system default template, select a custom template from your organization's library, or create a new template specific to that alert. You can also configure alerts to notify downstream asset owners with customizable depth settings.

## Breaking Changes

### Elasticsearch & Opensearch Version Changes

1. Elasticsearch server version: Verify whether the server is running version 8.x. If it is running an earlier version, please upgrade to 8.x before proceeding.
2. OpenSearch server version: Verify whether the server is running version 2.x. If it is running an earlier version, please upgrade to 2.x before proceeding.

### Collate - Deprecating Metapilot

We are removing the Metapilot UI in favor of the new Ask Collate features. We are not removing any functionality, but enhancing both the chat experience and query optimization agents.

- Instead of the floating Metapilot icon on the corner of the UI, now we have a dedicated AskCollate interface you can access from the navigation panel. There, you can interact with AskCollate to answer your questions both on data and metadata.

- The chat experience when analyzing queries in the Queries tab of table assets will now also use the new SQL Agent, while maintaining the existing experience.

### Deprecating Python 3.9

Python 3.9 became EOL in October 2025, and most of the Ingestion Framework dependencies already dropped its support.

We are now removing support for Python 3.9 in the ingestion framework and adding support for Python 3.12.

### Airflow 3.X will be the new default

As part of the python changes, we're also updating the default OSS ingestion image to be based on Airflow 3.X.

If you are still using 2.10.X in your own custom images, we will still support that version.

### POST `api/v1/dataQuality/testCases` Permission Change

We previously enforced the `EditTests` operations on the `Table` resource for creating test case permission. We have now introduced a new `CreateTests` operation on the `Table` resource for finer grain permission control over create vs edit tests for Table entities.

If you previously had an `EditTests` operation for a `Table` resource on your policy meant to prevent creation of test cases you will need to add the `CreateTests` operation as part of your policy.

## Changelog

### Fixes

- Security & dependencies: multiple vulnerability fixes and dependency updates (netty, commons-lang3, org.json, angus mail, protobuf) and pinned pydantic to <2.12.0 to address compatibility issues.
- UI fixes: resolved numerous UI bugs including import warning messages, left-sidebar settings icon, drawer loading overlay scroll behavior, Data Product icon stroke width, default font sizing and color, tab rendering and persona page issues, duplicate owners/tier fields, activity feed header/navigation and widget title widths, console warnings, lineage paging/rendering, edit-lineage button placement, description rendering on nonâ€‘Chromium browsers, and other component errors and warnings.
- Search & indexing: fixes for vector search index creation/validation, prevention of truncation in Elasticsearch indices (added explicit fqnHash and lineage mappings with ignore_above 512), restored missing search documents for incidents, and addressed large-parameter and indexing edge cases.
- Query Runner & DB fixes: enabled parallel execution for Query Runner; DB query fixes (SSO/OAuth); SELECT-only enforcement; saved-query per user; pagination added for Snowflake usage/lineage queries; various Snowflake/BigQuery CLI and query-related bug fixes.
- Data quality & dimensionality: fixes to Data Quality dashboard filtering, freshness tests, dimensionality validators, incident reporting and consolidated ChangeEvents for test runs; migrations and retention fixes for test case results and profile data.
- Connectors & lineage parsing: Databricks/DLT auth and parsing fixes, PowerBI native query lineage extraction and custom API URL fixes, Kafka Connect lineage and Confluent Cloud parsing fixes, BigQuery exporter bug fixes, Collibra connector fixes.
- API & backend fixes: domain assets count mismatch, glossary term circular/self-referential parent handling (preventing API hangs), table diff validation parameter (table2.keyColumns), support for datamodel source URL, explicit fixes for view-name scoping and local-variable issues, and prevention of double notifications on cover image upload failures.
- Authentication, tokens & SSO: LDAP login retry improvements, SAML/Azure AD timestamp compatibility, Support App token evaluation fixes, improved bot/OIDC handling, and explicit bearer-token error messaging.
- Migrations & reliability: migration fixes and adjustments for multiple versions (including 1.10.x â†’ 1.11.x moves), zero-downtime reindexing orphan cleanup, socket/connect timeout increases to 30s, fixes to prevent streamable log leaks, and other reliability fixes.
- Miscellaneous: fixed incidents and notification issues (missing Slack notifications for workflow-generated approval tasks, incorrect user/team URLs in notifications), improved Okta public key URL handling, fixed DBT and Snowflake integration issues, and numerous other cross-area bug fixes.

### Improvements

- Custom Workflows & UI: full implementation and UI revamp for Custom Workflows, Knowledge Center and Overview improvements, domain & data-product field support, project/explorer card enhancements, domain tree view, pipeline view node/edge support, and multiple UI styling and layout improvements across the app.
- AskCollate & AI experience: AskCollate UI and chat enhancements, CAIP-related pipe updates, agent improvements, AskCollate Slack integration and chat/profile components for messages.
- SQL & Query Runner enhancements: saved-query per user, improved userAuthConfig response for UI, improved logging, SELECT-only enforcement improvements, and performance/pagination improvements for Snowflake usage/lineage.
- Connectors & exporters: added or improved connectors and exporters including AWS Kinesis Firehose, BigQuery exporter, Collibra connector, Hex dashboard connector, Kafka Connect Confluent Cloud support, ADLS unstructured containers, Collibra and Hex integrations, and PowerBI improvements (custom API URL, databricks lineage parsing).
- Embeddings & vector search: DJL local embeddings support, efficient kâ€‘NN filtering, increased neighbor limits, soft/hard delete handling, embedding model tracking, and improved vector index validation.
- Data Observability & Data Quality as Code: new Data Quality as Code APIs, DataFrame/TestRunner improvements, support for dimension-level DQ tests and a wide set of dimensionality validators (mean, median, min/max, sum, stddev, regex, not-null, uniqueness, etc.), plus UI updates for dimensionality analysis and test result exploration.
- Notifications & templates: enhanced notification templates with rich formatting, Handlebars helpers, template preview and test send, transformers, and permission controls for templates; notification template UI added.
- Performance & reliability: ingestion log streaming & caching improvements (streaming + caching for downloads), Redis added as an optional cache, increased socket/connect timeouts to 30s, improved handling for streamable logs, and general performance tweaks.
- Search & indexing improvements: Search reindex enhancements (selective entity reindex), improved stemmer language support for OpenSearch, unified ES/OS client API with separate index management, and other search reliability improvements.
- Observability & tooling: added workflow resource utilisation metrics to aid troubleshooting, improved metrics page docs and messaging, and better logging and error messages across services.
- Miscellaneous improvements: Impersonation by bots, bulk update APIs for data assets, selective entity reindex for passed entity refs, added support for classification tags in dbt meta field, Kafka lineage support in Databricks pipelines, Hex & Collibra connectors, improved Tableau logging, and other end-user enhancements.

**Full Changelog**: [link](https://github.com/open-metadata/OpenMetadata/compare/1.10.14-release...1.11.0-release)
